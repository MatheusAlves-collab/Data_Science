{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Validação Cruzada <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validação cruzada se refere a maneira que serão divididos os dados de treino e teste do nosso modelo de predição, essa divisão geralmente é realizada várias vezes onde a medida de score do modelo é calculada realizadando uma media de todas as possibilidades modeladas. Essa tecnica geralmente requer um poder computacional bem relevante dependendo do número de subdivisões utilizados nos métodos, que podem ser:\n",
    "\n",
    "<ui>\n",
    "<li> K-Fold (K Dobras)\n",
    "<li> Stratified K-Fold\n",
    "<li> Leave One Out\n",
    "<ui>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>K-Fold<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse metódo consiste em separar os dados em $K$ subdivisões iguais, sendo que uma das subdivisões (Fold) será guardado para teste e as outras $(K-1)$ serão para treino, depois de realizar esse primeiro modelo e guardar sua pontuação ($R^2$), serão gerados outros $(K-1)$ modelos apenas mudando qual Fold será usada para teste e guardando sua pontuação para chegar em uma média final de desempenho. É recomendado usar um $K$ variando de 5 a 10 Folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza dos dados, dados de estudantes para serem adimitidos em um exame com base nas suas notas\n",
    "df_adm = pd.read_csv('Admission_Predict.csv')\n",
    "\n",
    "df_admiss = (df_adm.drop(['Serial No.'], axis='columns')).copy()\n",
    "\n",
    "x_admiss = df_admiss.loc[:, df_admiss.columns != 'Chance of Admit ']\n",
    "y_admiss = df_admiss.loc[:, df_admiss.columns == 'Chance of Admit ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7711794121066354\n"
     ]
    }
   ],
   "source": [
    "modelo = LinearRegression()\n",
    "kfold = KFold(n_splits= 5)\n",
    "resultado = cross_val_score(modelo, x_admiss, y_admiss, cv = kfold) # separa automaticamente treino e teste\n",
    "\n",
    "print(resultado.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelos_regressao_k_fold (dados_x, dados_y):\n",
    "    reg = LinearRegression()\n",
    "    lasso = Lasso()\n",
    "    ridge = Ridge()\n",
    "    elastic = ElasticNet(alpha = 1, l1_ratio= 0.5) # Parametros default\n",
    "    kfold = KFold(n_splits= 10)\n",
    "\n",
    "    reg_score = cross_val_score(reg, dados_x, dados_y, cv = kfold)\n",
    "    lasso_score = cross_val_score(lasso, dados_x, dados_y, cv = kfold)\n",
    "    ridge_score = cross_val_score(ridge, dados_x, dados_y, cv = kfold) \n",
    "    elastic_score = cross_val_score(elastic, dados_x, dados_y, cv = kfold) \n",
    "\n",
    "    dic_models = {'Linear':reg_score.mean() , 'Lasso':lasso_score.mean(), 'Ridge':ridge_score.mean(), 'Elastic':elastic_score.mean()}\n",
    "\n",
    "    print(\"Modelos K-Fold\")\n",
    "    print(\"Regressão Linear:\", reg_score.mean(), \"\\nLasso:\", lasso_score.mean(), \"\\nRidge:\", ridge_score.mean(), \"\\nElastic Net:\", elastic_score.mean())\n",
    "    print(\"O melhor modelo foi\",max(dic_models, key = dic_models.get),\"com valor\", max(dic_models.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos K-Fold\n",
      "Regressão Linear: 0.7703825020879949 \n",
      "Lasso: 0.18277276199791023 \n",
      "Ridge: 0.7705725482928705 \n",
      "Elastic Net: 0.49623767436974936\n",
      "O melhor modelo foi Ridge com valor 0.7705725482928705\n"
     ]
    }
   ],
   "source": [
    "modelos_regressao_k_fold(x_admiss, y_admiss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Stratified K-Fold<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse método funciona da mesma maneira que o K-Fold, porém ele mantém uma proporção fixa de classes da variável resposta ao longo das subdivisões com a intenção de não deixar algum dos $K$ folds com uma classe apenas, esse tipo de método funciona melhor em algotitimos de classificação. <br>\n",
    "\n",
    "Por exemplo se temos um conjunto de dados de alunos com 3% sendo aprovados, precisamos que essaa porcentagem de aprovados seja replicada ao longo de cada uma das subdivisões, do contrário poderiam haver folds apenas com dados de alunos reprovados, o que implicaria no modelo não conseguir treinar bem pra prever os aprovados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Leave One Out<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A técnica Leave One Out é utilizada quando se trata de pequenos conjuntos de dados, pois é necessário muito poder computacional. Neste caso, cada iteração é composta por um caso da base de dados sendo o conjunto de teste e o restante das observações compondo o conjunto de treinamento. No fim se trata de uma tecnica K-Fold onde o $K$ é a quantidade totais de linhas da tabela. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Ajustando parâmetros<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É importante saber alterar os parâmetros dos modelos para chegar em um que apresente um desempenho melhor, no caso da regressão linear elastic net podemos ajustar o valor do $\\lambda$ e do coeficiente $L1$ (Lasso) afim de encontrar o melhor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor Score: 0.7408292165331436\n",
      "Melhor Alpha: 0.1\n",
      "Melhor L1 Ratio: 0.02\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definindo valores para testar\n",
    "\n",
    "valores = {'alpha': [0.1,0.5,1,2,5,10,25,50,100,150,200,300,500,750,1000,1500,2000,3000,5000], 'l1_ratio': [0.02,0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]}\n",
    "\n",
    "modelo_aj = ElasticNet()\n",
    "procura1 = RandomizedSearchCV(estimator= modelo_aj, param_distributions= valores, n_iter= 150, cv = 5, random_state = 15) # cv = K-fold # Essa função testa 150 combinações possíveis\n",
    "procura = GridSearchCV(estimator= modelo_aj, param_grid= valores,  cv = 5) # Essa função testa todas as combinações possíveis\n",
    "procura.fit(x_admiss, y_admiss)\n",
    "\n",
    "print(\"Melhor Score:\", procura.best_score_)\n",
    "print(\"Melhor Alpha:\", procura.best_estimator_.alpha)\n",
    "print(\"Melhor L1 Ratio:\", procura.best_estimator_.l1_ratio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
