{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "pd.set_option('display.max_columns',68)\n",
    "pd.set_option('display.max_rows',68)\n",
    "\n",
    "# print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Regressão Logística <h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regressão logística é um metodo de previsão para classificar um evento com duas classes, 0 ou 1 e ela faz uso da função sigmoide, já que ela é ideal para descrever o comportamento de duas classes, ela usa como base a regressão linear como variável preditora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ f(Y) = \\frac{1} {1 + e^-Y }$$\n",
    "\n",
    "$$Y = \\beta_0 + \\beta_1*x_1 + \\beta_1*x_1 + ... +  \\beta_k*x_k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xlog = np.linspace(-10,10, 50)\n",
    "plt.plot(xlog, 1 / (1 + np.exp(-xlog)) , color = 'red')\n",
    "plt.title(\"Função Sigmóde\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se possuímos mais de uma classe pra prever o modelo irá gerar valores 0 ou 1 para cada classe, onde na predição final para um caso apenas uma das classes terá o valor 1 enquanto as outras ficarão com 0. No caso 4 classes serão geradas 4 equações diferentes e a classe que mais se aproxima de 1 será a classe que o modelo retornará como previsão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Avaliação de Desodorantes <h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi realizada uma pesquisa para avaliação de desodorantes onde o entrevistado responde se gostou ou não do produto com base em diversas qualidades listadas no questionario. Base de dados disponível em  https://www.kaggle.com/ramkumarr02/deodorant-instant-liking-data. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data_train_reduced.csv')\n",
    "\n",
    "percen_faltantes = round((df.isnull().sum() / len(df['Instant.Liking']) )*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limpeza\n",
    "df_desodorante = (df.drop(['q8.20', 'q8.18', 'q8.17', 'q8.8', 'q8.9', 'q8.10', 'q8.2', \n",
    "                           'Respondent.ID', 'Product', 'q1_1.personal.opinion.of.this.Deodorant'], axis='columns')).copy()\n",
    "\n",
    "df_desodorante['q8.12'].fillna(df_desodorante['q8.12'].median(), inplace= True ) \n",
    "df_desodorante['q8.7'].fillna(df_desodorante['q8.12'].median(), inplace= True ) \n",
    "\n",
    "tipos = df_desodorante.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_faltantes_new = round((df_desodorante.isnull().sum() / len(df_desodorante['Instant.Liking']) )*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_des = df_desodorante.drop(['Instant.Liking'], axis='columns')\n",
    "y_des = df_desodorante['Instant.Liking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia de 0.752\n"
     ]
    }
   ],
   "source": [
    "# Modelagem\n",
    "\n",
    "# Separando folds\n",
    "str_kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "#Criando modelo\n",
    "modelo_log = LogisticRegression()\n",
    "resultado = cross_val_score(modelo_log, x_des, y_des, cv = str_kfold)\n",
    "\n",
    "#Acurácia\n",
    "print('Acurácia de', resultado.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível utilizar os métodos de regularização Lasso e Ridge na regressão logística assim como foi feita na regressão linear, ou seja, iremos ajustar os parâmetros L1 e $\\lambda$ para localizar qual o melhor valor que otimiza nossa acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor Acurácia: 0.7544\n",
      "Parâmetro C: 0.5\n",
      "Regularização: l1\n"
     ]
    }
   ],
   "source": [
    "# Valores a serem testados\n",
    "Val_C = np.array([0.01, 0.1, 0.5, 1, 2, 3, 5, 10, 20, 50, 100])\n",
    "regul = ['l1' , 'l2']\n",
    "val_grid = {'C': Val_C, 'penalty': regul}\n",
    "\n",
    "#Criando modelo\n",
    "modelo_log1 = LogisticRegression(solver='liblinear') # Solver 'liblinear' suporta l1 e l2, \n",
    "                                                     # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "#Criando Grids\n",
    "procura = GridSearchCV(estimator= modelo_log1, param_grid= val_grid,  cv = 5) # Essa função testa todas as combinações possíveis\n",
    "procura.fit(x_des, y_des)\n",
    "\n",
    "#Imprimindo a melhor acurácia\n",
    "print(\"Melhor Acurácia:\", procura.best_score_)\n",
    "print(\"Parâmetro C:\", procura.best_estimator_.C)\n",
    "print(\"Regularização:\", procura.best_estimator_.penalty)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Predição Câncer de Mama<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados de mulheres com câncer do pacote Sklearn do Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mean radius mean texture mean perimeter mean area mean smoothness  \\\n",
       "0       17.99        10.38         122.80    1001.0         0.11840   \n",
       "1       20.57        17.77         132.90    1326.0         0.08474   \n",
       "2       19.69        21.25         130.00    1203.0         0.10960   \n",
       "3       11.42        20.38          77.58     386.1         0.14250   \n",
       "4       20.29        14.34         135.10    1297.0         0.10030   \n",
       "\n",
       "  mean compactness mean concavity mean concave points mean symmetry  \\\n",
       "0          0.27760         0.3001             0.14710        0.2419   \n",
       "1          0.07864         0.0869             0.07017        0.1812   \n",
       "2          0.15990         0.1974             0.12790        0.2069   \n",
       "3          0.28390         0.2414             0.10520        0.2597   \n",
       "4          0.13280         0.1980             0.10430        0.1809   \n",
       "\n",
       "  mean fractal dimension radius error texture error perimeter error  \\\n",
       "0                0.07871       1.0950        0.9053           8.589   \n",
       "1                0.05667       0.5435        0.7339           3.398   \n",
       "2                0.05999       0.7456        0.7869           4.585   \n",
       "3                0.09744       0.4956        1.1560           3.445   \n",
       "4                0.05883       0.7572        0.7813           5.438   \n",
       "\n",
       "  area error smoothness error compactness error concavity error  \\\n",
       "0     153.40         0.006399           0.04904         0.05373   \n",
       "1      74.08         0.005225           0.01308         0.01860   \n",
       "2      94.03         0.006150           0.04006         0.03832   \n",
       "3      27.23         0.009110           0.07458         0.05661   \n",
       "4      94.44         0.011490           0.02461         0.05688   \n",
       "\n",
       "  concave points error symmetry error fractal dimension error worst radius  \\\n",
       "0              0.01587        0.03003                0.006193        25.38   \n",
       "1              0.01340        0.01389                0.003532        24.99   \n",
       "2              0.02058        0.02250                0.004571        23.57   \n",
       "3              0.01867        0.05963                0.009208        14.91   \n",
       "4              0.01885        0.01756                0.005115        22.54   \n",
       "\n",
       "  worst texture worst perimeter worst area worst smoothness worst compactness  \\\n",
       "0         17.33          184.60     2019.0           0.1622            0.6656   \n",
       "1         23.41          158.80     1956.0           0.1238            0.1866   \n",
       "2         25.53          152.50     1709.0           0.1444            0.4245   \n",
       "3         26.50           98.87      567.7           0.2098            0.8663   \n",
       "4         16.67          152.20     1575.0           0.1374            0.2050   \n",
       "\n",
       "  worst concavity worst concave points worst symmetry worst fractal dimension  \n",
       "0          0.7119               0.2654         0.4601                 0.11890  \n",
       "1          0.2416               0.1860         0.2750                 0.08902  \n",
       "2          0.4504               0.2430         0.3613                 0.08758  \n",
       "3          0.6869               0.2575         0.6638                 0.17300  \n",
       "4          0.4000               0.1625         0.2364                 0.07678  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "dados = load_breast_cancer()\n",
    "\n",
    "x_can = pd.DataFrame(dados.data, columns= [dados.feature_names])\n",
    "y_can = pd.Series(dados.target)\n",
    "\n",
    "x_can.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_cancer_faltantes = round((x_can.isnull().sum() / x_can.shape[0] )*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(solver='liblinear'),\n",
       "             param_grid={'C': array([1.0e-02, 1.0e-01, 5.0e-01, 1.0e+00, 2.0e+00, 3.0e+00, 5.0e+00,\n",
       "       1.0e+01, 2.0e+01, 5.0e+01, 9.5e+01, 1.0e+02]),\n",
       "                         'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valores a serem testados\n",
    "Val_C_can = np.array([0.01, 0.1, 0.5, 1, 2, 3, 5, 10, 20, 50, 95, 100])\n",
    "regul_can = ['l1' , 'l2']\n",
    "val_grid_can = {'C': Val_C_can, 'penalty': regul_can}\n",
    "\n",
    "# Modelo\n",
    "modelo_log_cancer = LogisticRegression(solver='liblinear')\n",
    "\n",
    "#Criando Grids\n",
    "procura_can = GridSearchCV(estimator= modelo_log_cancer, param_grid= val_grid_can,  cv = 5) # Essa função testa todas as combinações possíveis\n",
    "procura_can.fit(x_can, y_can)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor Acurácia: 0.968390001552554\n",
      "Parâmetro C: 95.0\n",
      "Regularização: l1\n"
     ]
    }
   ],
   "source": [
    "#Imprimindo a melhor acurácia\n",
    "print(\"Melhor Acurácia:\", procura_can.best_score_)\n",
    "print(\"Parâmetro C:\", procura_can.best_estimator_.C)\n",
    "print(\"Regularização:\", procura_can.best_estimator_.penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Matriz de Confusão<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também conhecida como Matriz de Erro, a matriz de Confusão é uma tabela que indica a quantidade de  *falsos positivos*, *falsos negativos*, *verdadeiros positivos* e *verdadeiros negativos* da predição de um modelo de classificação.\n",
    "\n",
    "<ul>\n",
    "<li><b>Falso Negativo:</b> Quando o modelo preve resultado positivo, porém o resultado real é negativo, é o pior tipo de erro que pode ocorrer</li>\n",
    "<li><b>Falso Positivo:</b> Quando o modelo preve resultado positivo, porém o resultado real é negativo</li>\n",
    "<li><b>Verdadeiro Negativo:</b> Quando o modelo preve resultado negativo, e o resultado real é de fato negativo</li>\n",
    "<li><b>Verdadeiro Positivo:</b> Quando o modelo preve resultado positivo, e o resultado real é de fato positivo</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766081871345029"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Treino e teste\n",
    "X_treino, X_teste, Y_treino, Y_teste = train_test_split(x_can, y_can, test_size= 0.3, random_state=9)\n",
    "\n",
    "#Modelo\n",
    "modelo_cancer_final = LogisticRegression(C= 100, penalty= 'l1', solver='liblinear')\n",
    "modelo_cancer_final.fit(X_treino, Y_treino)\n",
    "\n",
    "predicao = modelo_cancer_final.predict(X_teste)\n",
    "\n",
    "resultado = modelo_cancer_final.score(X_teste, Y_teste)\n",
    "\n",
    "matriz = confusion_matrix(Y_teste, predicao)\n",
    "\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59,   3],\n",
       "       [  1, 108]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Sensibilidade, Especificidade e Curva ROC<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Sensibilidade</b> é a probabilidade de um resultado positivo de teste, dado que o indivíduo testado realmente tenha a doença (feature). O complementar da sensibilidade é o falso negativo.\n",
    "\n",
    "<b>Especificidade</b> é a probabilidade de um resultado negativo de teste, dado que o indivíduo testado não tenha a doença (feature). O complementar da especificidade é o falso positivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidade: 0.98\n",
      "Especificidade: 0.03\n"
     ]
    }
   ],
   "source": [
    "sensibilidade = matriz[0,0] / (matriz[0,0] + matriz[1,0])\n",
    "\n",
    "especificidade = matriz[0,1] / (matriz[0,1] + matriz[1,1])\n",
    "\n",
    "print(\"Sensibilidade:\", round(sensibilidade,2))\n",
    "print(\"Especificidade:\", round(especificidade,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Receiver Operator Characteristic Curve\n",
    "\n",
    "Uma curva ROC é um gráfico de linha que plota a probabilidde de um resultado positivo verdadeiro (sensibilidade do teste) versus a probalidade de um resultado falso positivo\n",
    "No geral, a sensibilidade e especificidade variam indiretamente proporcionais, na prática, é rara a\n",
    "existência de um teste que seja altamente sensível e específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicoes = modelo_cancer_final.predict_proba(X_teste)\n",
    "\n",
    "probs = predicoes[:,1]  # Probabilidades de pertence a classe 0 ou 1, limite é de 0,5. Abixo de 0,5 classe 0\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, limites = roc_curve(Y_teste, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR: [0.         0.00917431 0.94495413 0.94495413 0.98165138 0.98165138\n",
      " 0.99082569 0.99082569 1.         1.        ]\n",
      "FPR: [0.         0.         0.         0.03225806 0.03225806 0.0483871\n",
      " 0.0483871  0.11290323 0.11290323 1.        ]\n",
      "Limites: [2.00000000e+00 9.99999998e-01 8.93188643e-01 8.83423300e-01\n",
      " 7.01225205e-01 6.82363253e-01 6.20722235e-01 1.70541372e-01\n",
      " 1.19692022e-01 1.02215872e-51]\n"
     ]
    }
   ],
   "source": [
    "print('TPR:',tpr)\n",
    "print('FPR:',fpr)\n",
    "print('Limites:',limites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(fpr,tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9973364900858241\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(Y_teste,probs)) # Quanto maior a área embaixo da curva ROC melhor o modelo é"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
